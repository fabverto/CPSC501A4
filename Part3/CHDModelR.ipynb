{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHDModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1gCrXSWJMnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCTvjLqFJYRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_core.python.keras import regularizers\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ4WVuN1U_VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"heart_train.csv\"\n",
        "test_file = \"heart_test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2BDJMu6J42R",
        "colab_type": "code",
        "outputId": "9c6de094-f7f0-4018-b4d7-b8597f2cfc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!head {train_file}"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "row.names,sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd\r\n",
            "56,152,5.99,7.99,32.48,Absent,45,26.57,100.32,48,0\r\n",
            "57,118,0,2.99,16.17,Absent,49,23.83,3.22,28,0\r\n",
            "58,126,5.1,2.96,26.5,Absent,55,25.52,12.34,38,1\r\n",
            "59,103,0.03,4.21,18.96,Absent,48,22.94,2.62,18,0\r\n",
            "60,121,0.8,5.29,18.95,Present,47,22.51,0,61,0\r\n",
            "61,142,0.28,1.8,21.03,Absent,57,23.65,2.93,33,0\r\n",
            "62,138,1.15,5.09,27.87,Present,61,25.65,2.34,44,0\r\n",
            "63,152,10.1,4.71,24.65,Present,65,26.21,24.53,57,0\r\n",
            "64,140,0.45,4.3,24.33,Absent,41,27.23,10.08,38,0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KRV62YJ5bu",
        "colab_type": "code",
        "outputId": "4f592fe7-4125-48bd-b21e-a715657f8718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "!head {test_file}"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "row.names,sbp,tobacco,ldl,adiposity,famhist,typea,obesity,alcohol,age,chd\r\n",
            "1,150,13.8,5.1,29.45,Present,52,27.92,77.76,55,1\r\n",
            "2,176,6,3.98,17.2,Present,52,21.07,4.11,61,1\r\n",
            "3,142,2.2,3.29,22.7,Absent,44,23.66,5.66,42,1\r\n",
            "4,132,0,3.3,21.61,Absent,42,24.92,32.61,33,0\r\n",
            "5,142,1.32,7.63,29.98,Present,57,31.16,72.93,33,0\r\n",
            "6,146,1.16,2.28,34.53,Absent,50,28.71,45,49,0\r\n",
            "7,132,7.2,3.65,17.16,Present,56,23.25,0,34,0\r\n",
            "8,120,0,3.57,23.22,Absent,58,27.2,0,32,0\r\n",
            "9,118,0,3.89,15.96,Absent,65,20.18,0,16,0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUhMX9n6Z6ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zFwz2hibTn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self,names):\n",
        "    self.names = names\n",
        "  \n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC_awOYIbkj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file,\n",
        "      batch_size = 50,\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value =\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True,\n",
        "      **kwargs)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A82rug65KeSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'chd'\n",
        "LABELS = [0, 1]\n",
        "\n",
        "CATEGORIES = {'famhist': ['Present', 'Absent']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGiKzLPOKfuV",
        "colab_type": "code",
        "outputId": "f7cd1444-6f04-4c7c-d3cf-bc1322c5f9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "SELECT_COLUMNS = ['sbp','tobacco','ldl','adiposity','famhist', 'typea','obesity','alcohol','age','chd']\n",
        "raw_train_data = get_dataset(train_data, select_columns=SELECT_COLUMNS)\n",
        "raw_test_data = get_dataset(test_data, select_columns=SELECT_COLUMNS)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-266-32ffe5448233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSELECT_COLUMNS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sbp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tobacco'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ldl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'adiposity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'famhist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typea'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'obesity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'alcohol'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mraw_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSELECT_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mraw_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSELECT_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-264-80ed43fc5abe>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(file, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       **kwargs)\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/experimental/ops/readers.py\u001b[0m in \u001b[0;36mmake_csv_dataset_v2\u001b[0;34m(file_pattern, batch_size, column_names, column_defaults, label_name, select_columns, field_delim, use_quote_delim, na_value, header, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed, prefetch_buffer_size, num_parallel_reads, sloppy, num_rows_for_inference, compression_type, ignore_errors)\u001b[0m\n\u001b[1;32m    424\u001b[0m   \"\"\"\n\u001b[1;32m    425\u001b[0m   \u001b[0;31m# Create dataset of all matching filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m   \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_file_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/experimental/ops/readers.py\u001b[0m in \u001b[0;36m_get_file_names\u001b[0;34m(file_pattern, shuffle)\u001b[0m\n\u001b[1;32m    933\u001b[0m       \u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mlisting\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \"\"\"\n\u001b[0;32m--> 363\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_matching_files_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Convert the filenames to string from bytes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=g-complex-comprehension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[1;32m    392\u001b[0m             compat.as_bytes(single_filename))\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msingle_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[0;32m--> 392\u001b[0;31m             compat.as_bytes(single_filename))\n\u001b[0m\u001b[1;32m    393\u001b[0m     ]\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 71\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got (OrderedDict([('famhist', <tf.Tensor: id=160760, shape=(50,), dtype=string, numpy=\narray([b'Absent', b'Absent', b'Absent', b'Present', b'Present', b'Absent',\n       b'Absent', b'Present', b'Absent', b'Present', b'Absent',\n       b'Present', b'Absent', b'Present', b'Present', b'Absent',\n       b'Absent', b'Present', b'Absent', b'Absent', b'Present', b'Absent',\n       b'Absent', b'Absent', b'Absent', b'Absent', b'Present', b'Absent',\n       b'Present', b'Absent', b'Absent', b'Present', b'Absent', b'Absent',\n       b'Absent', b'Present', b'Absent', b'Absent', b'Present', b'Absent',\n       b'Present', b'Present', b'Present', b'Absent', b'Absent',\n       b'Present', b'Absent', b'Present', b'Absent', b'Absent'],\n      dtype=object)>), ('numeric', <tf.Tensor: id=160761, shape=(50, 8), dtype=float32, numpy=\narray([[1.220e+02, 0.000e+00, 3.760e+00, 2.459e+01, 5.600e+01, 2.436e+01,\n        0.000e+00, 3.000e+01],\n       [1.300e+02, 0.000e+00, 4.890e+00, 2.598e+01, 7.200e+01, 3.042e+01,\n        1.471e+01, 2.300e+01],\n       [1.180e+02, 0.000e+00, 2.390e+00, 1.213e+01, 4.900e+01, 1.846e+01,\n        2.600e-01, 1.700e+01],\n       [1.760e+02, 1.200e+00, 8.280e+00, 3.616e+01, 4.200e+01, 2.781e+01,\n        1.160e+01, 5.800e+01],\n       [1.460e+02, 5.080e+00, 7.030e+00, 2.741e+01, 6.300e+01, 3.646e+01,\n        2.448e+01, 3.700e+01],\n       [1.340e+02, 3.000e+00, 4.370e+00, 2.307e+01, 5.600e+01, 2.054e+01,\n        9.650e+00, 6.200e+01],\n       [1.480e+02, 4.500e+00, 1.049e+01, 3.327e+01, 5.000e+01, 2.592e+01,\n        2.060e+00, 5.300e+01],\n       [1.340e+02, 4.800e+00, 6.580e+00, 2.989e+01, 5.500e+01, 2.473e+01,\n        2.366e+01, 6.300e+01],\n       [1.380e+02, 6.000e+00, 7.240e+00, 3.705e+01, 3.800e+01, 2.869e+01,\n        0.000e+00, 5.900e+01],\n       [1.420e+02, 1.320e+00, 7.630e+00, 2.998e+01, 5.700e+01, 3.116e+01,\n        7.293e+01, 3.300e+01],\n       [1.420e+02, 7.440e+00, 5.520e+00, 3.397e+01, 4.700e+01, 2.929e+01,\n        2.427e+01, 5.400e+01],\n       [1.540e+02, 5.530e+00, 3.200e+00, 2.881e+01, 6.100e+01, 2.615e+01,\n        4.279e+01, 4.200e+01],\n       [1.420e+02, 0.000e+00, 3.540e+00, 1.664e+01, 5.800e+01, 2.597e+01,\n        8.360e+00, 2.700e+01],\n       [1.230e+02, 8.600e+00, 1.117e+01, 3.528e+01, 7.000e+01, 3.314e+01,\n        0.000e+00, 5.900e+01],\n       [1.680e+02, 9.000e+00, 8.530e+00, 2.448e+01, 6.900e+01, 2.618e+01,\n        4.630e+00, 5.400e+01],\n       [1.340e+02, 1.500e+00, 3.730e+00, 2.153e+01, 4.100e+01, 2.470e+01,\n        1.111e+01, 3.000e+01],\n       [1.220e+02, 0.000e+00, 3.080e+00, 1.630e+01, 4.300e+01, 2.213e+01,\n        0.000e+00, 1.600e+01],\n       [1.220e+02, 1.000e+00, 5.880e+00, 3.481e+01, 6.900e+01, 3.127e+01,\n        1.594e+01, 4.000e+01],\n       [1.400e+02, 4.500e-01, 4.300e+00, 2.433e+01, 4.100e+01, 2.723e+01,\n        1.008e+01, 3.800e+01],\n       [1.080e+02, 1.500e+00, 4.330e+00, 2.499e+01, 6.600e+01, 2.229e+01,\n        2.160e+01, 6.100e+01],\n       [1.400e+02, 0.000e+00, 2.400e+00, 2.789e+01, 7.000e+01, 3.074e+01,\n        1.440e+02, 2.900e+01],\n       [1.380e+02, 0.000e+00, 2.680e+00, 1.704e+01, 4.200e+01, 2.216e+01,\n        0.000e+00, 1.600e+01],\n       [1.240e+02, 0.000e+00, 3.040e+00, 1.733e+01, 4.900e+01, 2.204e+01,\n        0.000e+00, 1.800e+01],\n       [1.620e+02, 2.920e+00, 3.630e+00, 3.133e+01, 6.200e+01, 3.159e+01,\n        1.851e+01, 4.200e+01],\n       [1.340e+02, 1.200e+01, 4.960e+00, 2.979e+01, 5.300e+01, 2.486e+01,\n        8.230e+00, 5.700e+01],\n       [1.260e+02, 0.000e+00, 3.570e+00, 2.601e+01, 6.100e+01, 2.630e+01,\n        7.970e+00, 4.700e+01],\n       [1.180e+02, 1.050e+00, 3.160e+00, 1.298e+01, 4.600e+01, 2.209e+01,\n        1.635e+01, 3.100e+01],\n       [1.220e+02, 0.000e+00, 3.370e+00, 1.610e+01, 6.700e+01, 2.106e+01,\n        0.000e+00, 3.200e+01],\n       [1.300e+02, 7.280e+00, 3.560e+00, 2.329e+01, 2.000e+01, 2.680e+01,\n        5.187e+01, 5.800e+01],\n       [2.180e+02, 1.120e+01, 2.770e+00, 3.079e+01, 3.800e+01, 2.486e+01,\n        9.093e+01, 4.800e+01],\n       [1.740e+02, 0.000e+00, 3.860e+00, 2.173e+01, 4.200e+01, 2.337e+01,\n        0.000e+00, 6.300e+01],\n       [1.380e+02, 0.000e+00, 1.860e+00, 1.835e+01, 5.900e+01, 2.538e+01,\n        6.510e+00, 1.700e+01],\n       [1.100e+02, 1.216e+01, 4.990e+00, 2.856e+01, 4.400e+01, 2.714e+01,\n        2.160e+01, 5.500e+01],\n       [1.940e+02, 1.700e+00, 6.320e+00, 3.367e+01, 4.700e+01, 3.016e+01,\n        1.900e-01, 5.600e+01],\n       [1.280e+02, 4.200e-01, 4.600e+00, 2.668e+01, 4.100e+01, 3.097e+01,\n        1.033e+01, 3.100e+01],\n       [2.080e+02, 5.040e+00, 5.190e+00, 2.071e+01, 5.200e+01, 2.512e+01,\n        2.427e+01, 5.800e+01],\n       [1.270e+02, 0.000e+00, 2.810e+00, 1.570e+01, 4.200e+01, 2.203e+01,\n        1.030e+00, 1.700e+01],\n       [1.600e+02, 7.770e+00, 8.070e+00, 3.480e+01, 6.400e+01, 3.115e+01,\n        0.000e+00, 6.200e+01],\n       [1.700e+02, 4.200e+00, 4.670e+00, 3.545e+01, 5.000e+01, 2.714e+01,\n        7.920e+00, 6.000e+01],\n       [1.160e+02, 3.000e+00, 3.050e+00, 3.031e+01, 4.100e+01, 2.363e+01,\n        8.600e-01, 4.400e+01],\n       [1.540e+02, 2.400e+00, 5.630e+00, 4.217e+01, 5.900e+01, 3.507e+01,\n        1.286e+01, 5.000e+01],\n       [1.360e+02, 3.150e+00, 4.370e+00, 2.022e+01, 5.900e+01, 2.512e+01,\n        4.716e+01, 3.100e+01],\n       [1.360e+02, 1.360e+00, 3.160e+00, 1.497e+01, 5.600e+01, 2.498e+01,\n        7.300e+00, 2.400e+01],\n       [1.820e+02, 4.200e+00, 4.410e+00, 3.210e+01, 5.200e+01, 2.861e+01,\n        1.872e+01, 5.200e+01],\n       [1.700e+02, 0.000e+00, 3.120e+00, 3.715e+01, 4.700e+01, 3.542e+01,\n        0.000e+00, 5.300e+01],\n       [1.360e+02, 4.000e-01, 3.910e+00, 2.110e+01, 6.300e+01, 2.230e+01,\n        0.000e+00, 5.600e+01],\n       [1.520e+02, 3.000e+00, 4.640e+00, 3.129e+01, 4.100e+01, 2.934e+01,\n        4.530e+00, 4.000e+01],\n       [1.240e+02, 1.040e+00, 2.840e+00, 1.642e+01, 4.600e+01, 2.017e+01,\n        0.000e+00, 6.100e+01],\n       [1.280e+02, 2.000e+00, 6.130e+00, 2.131e+01, 6.600e+01, 2.286e+01,\n        1.183e+01, 6.000e+01],\n       [1.500e+02, 0.000e+00, 4.990e+00, 2.773e+01, 5.700e+01, 3.092e+01,\n        8.330e+00, 2.400e+01]], dtype=float32)>)]), <tf.Tensor: id=160762, shape=(50,), dtype=int32, numpy=\narray([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n       0, 1, 0, 0, 0, 0], dtype=int32)>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qole6DDLdTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, label_batch = next(iter(raw_train_data))\n",
        "test_batch, label_batch = next(iter(raw_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzKaCc2ULlGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['sbp','tobacco','ldl','adiposity', 'typea','obesity','alcohol','age']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMMGtsigLtGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch, label_batch = next(iter(packed_train_data))\n",
        "test_batch, label_batch = next(iter(packed_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXRIWkALx2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desc = pd.read_csv(sys.argv[1])[NUMERIC_FEATURES].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmFVmsqmL6FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIG6dDspMHan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8b1KSi7MMBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a8e88df-76ed-4919-8348-032ae4551cd0"
      },
      "source": [
        "train_batch['numeric']"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=160839, shape=(50, 8), dtype=float32, numpy=\n",
              "array([[1.5800e+02, 3.6000e+00, 2.9700e+00, 3.0110e+01, 6.3000e+01,\n",
              "        2.6640e+01, 1.0800e+02, 6.4000e+01],\n",
              "       [1.5200e+02, 5.9900e+00, 7.9900e+00, 3.2480e+01, 4.5000e+01,\n",
              "        2.6570e+01, 1.0032e+02, 4.8000e+01],\n",
              "       [1.3600e+02, 3.4600e+00, 6.3800e+00, 3.2250e+01, 4.3000e+01,\n",
              "        2.8730e+01, 3.1300e+00, 4.3000e+01],\n",
              "       [1.5000e+02, 1.8000e-01, 4.1400e+00, 1.4400e+01, 5.3000e+01,\n",
              "        2.3430e+01, 7.7100e+00, 4.4000e+01],\n",
              "       [1.5600e+02, 0.0000e+00, 3.4700e+00, 2.1100e+01, 7.3000e+01,\n",
              "        2.8400e+01, 0.0000e+00, 3.6000e+01],\n",
              "       [1.6200e+02, 6.9400e+00, 4.5500e+00, 3.3360e+01, 5.2000e+01,\n",
              "        2.7090e+01, 3.2060e+01, 4.3000e+01],\n",
              "       [1.3400e+02, 6.4000e+00, 8.4900e+00, 3.7250e+01, 5.6000e+01,\n",
              "        2.8940e+01, 1.0490e+01, 5.1000e+01],\n",
              "       [1.2000e+02, 0.0000e+00, 5.0100e+00, 2.6130e+01, 6.4000e+01,\n",
              "        2.6210e+01, 1.2240e+01, 3.3000e+01],\n",
              "       [1.1800e+02, 1.2000e-01, 1.9600e+00, 2.0310e+01, 3.7000e+01,\n",
              "        2.0010e+01, 2.4200e+00, 1.8000e+01],\n",
              "       [1.6600e+02, 3.0000e+00, 3.8200e+00, 2.6750e+01, 4.5000e+01,\n",
              "        2.0860e+01, 0.0000e+00, 6.3000e+01],\n",
              "       [1.6800e+02, 4.5000e+00, 6.6800e+00, 2.8470e+01, 4.3000e+01,\n",
              "        2.4250e+01, 2.4380e+01, 5.6000e+01],\n",
              "       [1.7000e+02, 0.0000e+00, 3.1200e+00, 3.7150e+01, 4.7000e+01,\n",
              "        3.5420e+01, 0.0000e+00, 5.3000e+01],\n",
              "       [1.3200e+02, 0.0000e+00, 6.6300e+00, 2.9580e+01, 3.7000e+01,\n",
              "        2.9410e+01, 2.5700e+00, 6.2000e+01],\n",
              "       [1.4800e+02, 0.0000e+00, 3.8400e+00, 1.7260e+01, 7.0000e+01,\n",
              "        2.0000e+01, 0.0000e+00, 2.1000e+01],\n",
              "       [1.2200e+02, 4.0000e+00, 5.2400e+00, 2.7890e+01, 4.5000e+01,\n",
              "        2.6520e+01, 0.0000e+00, 6.1000e+01],\n",
              "       [1.2800e+02, 5.1600e+00, 4.9000e+00, 3.1350e+01, 5.7000e+01,\n",
              "        2.6420e+01, 0.0000e+00, 6.4000e+01],\n",
              "       [1.3800e+02, 0.0000e+00, 3.2400e+00, 2.7680e+01, 6.0000e+01,\n",
              "        2.5700e+01, 8.8660e+01, 2.9000e+01],\n",
              "       [1.2600e+02, 1.8000e+00, 6.2200e+00, 1.9710e+01, 6.5000e+01,\n",
              "        2.4810e+01, 6.9000e-01, 3.1000e+01],\n",
              "       [1.6600e+02, 6.0000e+00, 3.0200e+00, 2.9300e+01, 3.5000e+01,\n",
              "        2.4380e+01, 3.8060e+01, 6.1000e+01],\n",
              "       [1.3800e+02, 1.1500e+00, 5.0900e+00, 2.7870e+01, 6.1000e+01,\n",
              "        2.5650e+01, 2.3400e+00, 4.4000e+01],\n",
              "       [1.3600e+02, 1.7000e+00, 3.5300e+00, 2.0130e+01, 5.6000e+01,\n",
              "        1.9440e+01, 1.4400e+01, 5.5000e+01],\n",
              "       [1.4200e+02, 4.4800e+00, 3.5700e+00, 1.9750e+01, 5.1000e+01,\n",
              "        2.3540e+01, 3.2900e+00, 4.9000e+01],\n",
              "       [1.2300e+02, 8.6000e+00, 1.1170e+01, 3.5280e+01, 7.0000e+01,\n",
              "        3.3140e+01, 0.0000e+00, 5.9000e+01],\n",
              "       [1.3400e+02, 0.0000e+00, 3.6900e+00, 1.3920e+01, 4.3000e+01,\n",
              "        2.7660e+01, 0.0000e+00, 1.9000e+01],\n",
              "       [1.2800e+02, 0.0000e+00, 1.0580e+01, 3.1810e+01, 4.6000e+01,\n",
              "        2.8410e+01, 1.4660e+01, 4.8000e+01],\n",
              "       [1.7400e+02, 0.0000e+00, 3.2700e+00, 3.5400e+01, 5.8000e+01,\n",
              "        3.7710e+01, 2.4950e+01, 4.4000e+01],\n",
              "       [1.1200e+02, 1.4400e+00, 2.7100e+00, 2.2920e+01, 5.9000e+01,\n",
              "        2.4810e+01, 0.0000e+00, 5.2000e+01],\n",
              "       [1.3000e+02, 5.6000e-01, 3.3000e+00, 3.0860e+01, 4.9000e+01,\n",
              "        2.7520e+01, 3.3330e+01, 4.5000e+01],\n",
              "       [1.4600e+02, 4.3600e+00, 4.3100e+00, 1.8440e+01, 4.7000e+01,\n",
              "        2.4720e+01, 1.0800e+01, 3.8000e+01],\n",
              "       [1.3800e+02, 6.0000e-02, 4.1500e+00, 2.0660e+01, 4.9000e+01,\n",
              "        2.2590e+01, 2.4900e+00, 1.6000e+01],\n",
              "       [1.2000e+02, 0.0000e+00, 3.9800e+00, 1.3190e+01, 4.7000e+01,\n",
              "        2.1890e+01, 0.0000e+00, 1.6000e+01],\n",
              "       [1.5300e+02, 7.8000e+00, 3.9600e+00, 2.5730e+01, 5.4000e+01,\n",
              "        2.5910e+01, 2.7030e+01, 4.5000e+01],\n",
              "       [1.3400e+02, 1.1790e+01, 4.0100e+00, 2.6570e+01, 3.8000e+01,\n",
              "        2.1790e+01, 3.8880e+01, 6.1000e+01],\n",
              "       [1.1800e+02, 1.6200e+00, 9.0100e+00, 2.1700e+01, 5.9000e+01,\n",
              "        2.5890e+01, 2.1190e+01, 4.0000e+01],\n",
              "       [1.5600e+02, 3.0200e+00, 5.3500e+00, 2.5720e+01, 5.3000e+01,\n",
              "        2.5220e+01, 2.8110e+01, 5.2000e+01],\n",
              "       [1.3800e+02, 8.8000e+00, 3.1200e+00, 2.2410e+01, 6.3000e+01,\n",
              "        2.3330e+01, 1.2003e+02, 5.5000e+01],\n",
              "       [1.4200e+02, 1.3200e+00, 7.6300e+00, 2.9980e+01, 5.7000e+01,\n",
              "        3.1160e+01, 7.2930e+01, 3.3000e+01],\n",
              "       [1.4200e+02, 0.0000e+00, 4.3200e+00, 2.5220e+01, 4.7000e+01,\n",
              "        2.8920e+01, 6.5300e+00, 3.4000e+01],\n",
              "       [1.3800e+02, 6.0000e+00, 7.2400e+00, 3.7050e+01, 3.8000e+01,\n",
              "        2.8690e+01, 0.0000e+00, 5.9000e+01],\n",
              "       [1.2400e+02, 6.0000e+00, 5.2100e+00, 3.3020e+01, 6.4000e+01,\n",
              "        2.9370e+01, 7.6100e+00, 5.8000e+01],\n",
              "       [1.3800e+02, 2.2700e+00, 6.4100e+00, 2.9070e+01, 5.8000e+01,\n",
              "        3.0220e+01, 2.9300e+00, 3.2000e+01],\n",
              "       [1.1800e+02, 0.0000e+00, 2.3900e+00, 1.2130e+01, 4.9000e+01,\n",
              "        1.8460e+01, 2.6000e-01, 1.7000e+01],\n",
              "       [1.6600e+02, 6.0000e+00, 8.8000e+00, 3.7890e+01, 3.9000e+01,\n",
              "        2.8700e+01, 4.3200e+01, 5.2000e+01],\n",
              "       [1.5200e+02, 3.0000e+00, 4.6400e+00, 3.1290e+01, 4.1000e+01,\n",
              "        2.9340e+01, 4.5300e+00, 4.0000e+01],\n",
              "       [1.4800e+02, 0.0000e+00, 5.3200e+00, 2.6710e+01, 5.2000e+01,\n",
              "        3.2210e+01, 3.2780e+01, 2.7000e+01],\n",
              "       [1.2200e+02, 2.8000e-01, 4.1900e+00, 1.9970e+01, 6.1000e+01,\n",
              "        2.5630e+01, 0.0000e+00, 2.4000e+01],\n",
              "       [1.3600e+02, 0.0000e+00, 5.0000e+00, 2.7580e+01, 4.9000e+01,\n",
              "        2.7590e+01, 1.4700e+00, 3.9000e+01],\n",
              "       [1.2800e+02, 0.0000e+00, 3.0900e+00, 2.0570e+01, 5.4000e+01,\n",
              "        2.5630e+01, 5.1000e-01, 1.7000e+01],\n",
              "       [1.3800e+02, 8.7000e-01, 1.8700e+00, 1.5890e+01, 4.4000e+01,\n",
              "        2.6760e+01, 4.2990e+01, 3.1000e+01],\n",
              "       [1.2400e+02, 1.8000e+00, 3.7400e+00, 1.6640e+01, 4.2000e+01,\n",
              "        2.2260e+01, 1.0490e+01, 2.0000e+01]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7_Sg_x0MODw",
        "colab_type": "code",
        "outputId": "4066e74d-fc77-45c3-ebd7-8c811cb9aefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(train_batch).numpy()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9196036 ,  0.01833139, -0.8793434 ,  0.6086808 ,  1.05311   ,\n",
              "         0.16786164,  3.648268  ,  1.4476614 ],\n",
              "       [ 0.6305482 ,  0.5383526 ,  1.6714802 ,  0.9113547 , -0.7746761 ,\n",
              "         0.15096642,  3.3395646 ,  0.36308125],\n",
              "       [-0.1402663 , -0.01213008,  0.85338753,  0.8819814 , -0.9777634 ,\n",
              "         0.672307  , -0.5670614 ,  0.02414994],\n",
              "       [ 0.5341964 , -0.72579944, -0.28482878, -1.3976529 ,  0.03767331,\n",
              "        -0.6069082 , -0.38296485,  0.0919362 ],\n",
              "       [ 0.8232518 , -0.7649642 , -0.6252773 , -0.5419918 ,  2.0685468 ,\n",
              "         0.59265774, -0.6928742 , -0.4503539 ],\n",
              "       [ 1.1123072 ,  0.74505574, -0.0764944 ,  1.0237402 , -0.06387036,\n",
              "         0.27647445,  0.595802  ,  0.02414994],\n",
              "       [-0.2366181 ,  0.6275614 ,  1.9255463 ,  1.5205344 ,  0.34230432,\n",
              "         0.72299314, -0.27122065,  0.56644005],\n",
              "       [-0.9110808 , -0.7649642 ,  0.15724644,  0.10039238,  1.1546537 ,\n",
              "         0.06407617, -0.20087807, -0.6537127 ],\n",
              "       [-1.0074326 , -0.7388544 , -1.3925569 , -0.6428833 , -1.5870254 ,\n",
              "        -1.4323642 , -0.5956004 , -1.6705066 ],\n",
              "       [ 1.3050108 , -0.11221786, -0.44743106,  0.17957306, -0.7746761 ,\n",
              "        -1.227207  , -0.6928742 ,  1.3798752 ],\n",
              "       [ 1.4013627 ,  0.21415532,  1.0058271 ,  0.39923522, -0.9777634 ,\n",
              "        -0.40899193,  0.28709847,  0.90537137],\n",
              "       [ 1.4977144 , -0.7649642 , -0.80312365,  1.5077635 , -0.5715887 ,\n",
              "         2.2870145 , -0.6928742 ,  0.70201254],\n",
              "       [-0.3329699 , -0.7649642 ,  0.9804206 ,  0.54099405, -1.5870254 ,\n",
              "         0.8364328 , -0.5895711 ,  1.312089  ],\n",
              "       [ 0.43784454, -0.7649642 , -0.43726844, -1.0324005 ,  1.7639158 ,\n",
              "        -1.4347779 , -0.6928742 , -1.4671478 ],\n",
              "       [-0.814729  ,  0.10536426,  0.2741166 ,  0.32516307, -0.7746761 ,\n",
              "         0.13889854, -0.6928742 ,  1.2443026 ],\n",
              "       [-0.5256735 ,  0.35775948,  0.10135183,  0.76704186,  0.44384798,\n",
              "         0.11476231, -0.6928742 ,  1.4476614 ],\n",
              "       [-0.04391449, -0.7649642 , -0.7421477 ,  0.29834396,  0.748479  ,\n",
              "        -0.05901773,  2.8708823 , -0.92485774],\n",
              "       [-0.6220253 , -0.3733164 ,  0.7720862 , -0.71950966,  1.2561973 ,\n",
              "        -0.2738297 , -0.6651391 , -0.7892852 ],\n",
              "       [ 1.3050108 ,  0.5405285 , -0.8539368 ,  0.505235  , -1.7901127 ,\n",
              "        -0.37761515,  0.8369766 ,  1.2443026 ],\n",
              "       [-0.04391449, -0.51474476,  0.19789697,  0.32260904,  0.8500227 ,\n",
              "        -0.07108608, -0.5988161 ,  0.0919362 ],\n",
              "       [-0.1402663 , -0.3950746 , -0.5947894 , -0.6658712 ,  0.34230432,\n",
              "        -1.5699401 , -0.11405523,  0.8375851 ],\n",
              "       [ 0.14878912,  0.20980369, -0.5744641 , -0.7144011 , -0.16541404,\n",
              "        -0.5803583 , -0.56063014,  0.43086752],\n",
              "       [-0.76655304,  1.1062421 ,  3.2873409 ,  1.2689444 ,  1.7639158 ,\n",
              "         1.7367107 , -0.6928742 ,  1.1087302 ],\n",
              "       [-0.2366181 , -0.7649642 , -0.5134882 , -1.458954  , -0.9777634 ,\n",
              "         0.41405037, -0.6928742 , -1.6027204 ],\n",
              "       [-0.5256735 , -0.7649642 ,  2.9875429 ,  0.8257886 , -0.67313236,\n",
              "         0.59507143, -0.10360432,  0.36308125],\n",
              "       [ 1.690418  , -0.7649642 , -0.72690374,  1.2842699 ,  0.5453917 ,\n",
              "         2.8397322 ,  0.3100101 ,  0.0919362 ],\n",
              "       [-1.2964879 , -0.45164597, -1.0114578 , -0.30955854,  0.64693534,\n",
              "        -0.2738297 , -0.6928742 ,  0.6342263 ],\n",
              "       [-0.42932174, -0.64311826, -0.7116598 ,  0.7044637 , -0.36850137,\n",
              "         0.38025993,  0.64685065,  0.15972246],\n",
              "       [ 0.34149274,  0.18369386, -0.19844626, -0.88170195, -0.5715887 ,\n",
              "        -0.29555225, -0.25875995, -0.31478137],\n",
              "       [-0.04391449, -0.7519093 , -0.27974734, -0.5981845 , -0.36850137,\n",
              "        -0.80965185, -0.5927867 , -1.8060791 ],\n",
              "       [-0.9110808 , -0.7649642 , -0.36612985, -1.5521828 , -0.5715887 ,\n",
              "        -0.978605  , -0.6928742 , -1.8060791 ],\n",
              "       [ 0.67872405,  0.93217635, -0.3762925 ,  0.04930819,  0.13921699,\n",
              "        -0.00833206,  0.3936173 ,  0.15972246],\n",
              "       [-0.2366181 ,  1.8003289 , -0.35088578,  0.15658511, -1.4854817 ,\n",
              "        -1.0027407 ,  0.86993706,  1.2443026 ],\n",
              "       [-1.0074326 , -0.4124812 ,  2.1897752 , -0.46536538,  0.64693534,\n",
              "        -0.0131594 ,  0.15887403, -0.17920884],\n",
              "       [ 0.8232518 , -0.10786622,  0.33001122,  0.04803105,  0.03767331,\n",
              "        -0.17487155,  0.4370287 ,  0.6342263 ],\n",
              "       [-0.04391449,  1.1497585 , -0.80312365, -0.37469098,  1.05311   ,\n",
              "        -0.63104445,  4.131823  ,  0.8375851 ],\n",
              "       [ 0.14878912, -0.47775578,  1.4885528 ,  0.59207827,  0.44384798,\n",
              "         1.2588153 ,  2.2386026 , -0.6537127 ],\n",
              "       [ 0.14878912, -0.7649642 , -0.19336483, -0.01582425, -0.5715887 ,\n",
              "         0.7181658 , -0.43039584, -0.5859264 ],\n",
              "       [-0.04391449,  0.5405285 ,  1.2903811 ,  1.4949921 , -1.4854817 ,\n",
              "         0.6626528 , -0.6928742 ,  1.1087302 ],\n",
              "       [-0.7183772 ,  0.5405285 ,  0.25887278,  0.9803186 ,  1.1546537 ,\n",
              "         0.8267786 , -0.3869844 ,  1.0409439 ],\n",
              "       [-0.04391449, -0.2710528 ,  0.86863136,  0.4758616 ,  0.5453917 ,\n",
              "         1.0319355 , -0.5751006 , -0.72149897],\n",
              "       [-1.0074326 , -0.7649642 , -1.17406   , -1.6875559 , -0.36850137,\n",
              "        -1.8064747 , -0.6824233 , -1.7382929 ],\n",
              "       [ 1.3050108 ,  0.5405285 ,  2.0830677 ,  1.602269  , -1.3839381 ,\n",
              "         0.6650665 ,  1.0435828 ,  0.6342263 ],\n",
              "       [ 0.6305482 , -0.11221786, -0.03076267,  0.7593793 , -1.1808507 ,\n",
              "         0.8195376 , -0.51078737, -0.17920884],\n",
              "       [ 0.43784454, -0.7649642 ,  0.3147674 ,  0.17446452, -0.06387036,\n",
              "         1.5122446 ,  0.62474287, -1.0604303 ],\n",
              "       [-0.814729  , -0.70404124, -0.25942206, -0.6863049 ,  0.8500227 ,\n",
              "        -0.07591342, -0.6928742 , -1.263789  ],\n",
              "       [-0.1402663 , -0.7649642 ,  0.152165  ,  0.28557286, -0.36850137,\n",
              "         0.39715517, -0.63378644, -0.2469951 ],\n",
              "       [-0.5256735 , -0.7649642 , -0.8183676 , -0.6096785 ,  0.13921699,\n",
              "        -0.07591342, -0.67237437, -1.7382929 ],\n",
              "       [-0.04391449, -0.5756678 , -1.4382889 , -1.2073641 , -0.87621975,\n",
              "         0.19682522,  1.0351417 , -0.7892852 ],\n",
              "       [-0.7183772 , -0.3733164 , -0.4880816 , -1.1115812 , -1.0793071 ,\n",
              "        -0.88930106, -0.27122065, -1.534934  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BXNmG65MXZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pALQEo_jMfuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FC9IMOiMnQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.005)),\n",
        "  layers.Dropout(0.5),\n",
        "   layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.005)),\n",
        "  layers.Dropout(0.5),\n",
        "   layers.Dense(128, activation='selu',kernel_regularizer=regularizers.l2(0.005)),\n",
        "  layers.Dropout(0.4),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkG6eoWaMqeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6H_AExPMsa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10bd403d-ffac-4626-8ee6-fb8ef4c4376b"
      },
      "source": [
        "\n",
        "print(\"--Train--\")\n",
        "model.fit(train_data, epochs=500)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy * 100))"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Train--\n",
            "Epoch 1/500\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 2.2007 - accuracy: 0.6413\n",
            "Epoch 2/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0744 - accuracy: 0.6929\n",
            "Epoch 3/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9250 - accuracy: 0.6978\n",
            "Epoch 4/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8396 - accuracy: 0.7174\n",
            "Epoch 5/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8032 - accuracy: 0.7150\n",
            "Epoch 6/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6917 - accuracy: 0.7322\n",
            "Epoch 7/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5863 - accuracy: 0.7297\n",
            "Epoch 8/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5452 - accuracy: 0.7052\n",
            "Epoch 9/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4618 - accuracy: 0.7273\n",
            "Epoch 10/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4028 - accuracy: 0.7543\n",
            "Epoch 11/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3802 - accuracy: 0.7396\n",
            "Epoch 12/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3074 - accuracy: 0.7592\n",
            "Epoch 13/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2709 - accuracy: 0.7445\n",
            "Epoch 14/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2301 - accuracy: 0.7273\n",
            "Epoch 15/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2026 - accuracy: 0.7592\n",
            "Epoch 16/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1701 - accuracy: 0.7297\n",
            "Epoch 17/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1095 - accuracy: 0.7494\n",
            "Epoch 18/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0911 - accuracy: 0.7396\n",
            "Epoch 19/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0339 - accuracy: 0.7641\n",
            "Epoch 20/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0248 - accuracy: 0.7617\n",
            "Epoch 21/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0167 - accuracy: 0.7494\n",
            "Epoch 22/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9825 - accuracy: 0.7469\n",
            "Epoch 23/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9588 - accuracy: 0.7641\n",
            "Epoch 24/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9412 - accuracy: 0.7592\n",
            "Epoch 25/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9107 - accuracy: 0.7764\n",
            "Epoch 26/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8939 - accuracy: 0.7592\n",
            "Epoch 27/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8436 - accuracy: 0.7715\n",
            "Epoch 28/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8530 - accuracy: 0.7518\n",
            "Epoch 29/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8147 - accuracy: 0.7568\n",
            "Epoch 30/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8240 - accuracy: 0.7690\n",
            "Epoch 31/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8084 - accuracy: 0.7617\n",
            "Epoch 32/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8137 - accuracy: 0.7641\n",
            "Epoch 33/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7441 - accuracy: 0.7494\n",
            "Epoch 34/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7824 - accuracy: 0.7617\n",
            "Epoch 35/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7221 - accuracy: 0.7740\n",
            "Epoch 36/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7760 - accuracy: 0.7666\n",
            "Epoch 37/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7617 - accuracy: 0.7641\n",
            "Epoch 38/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6977 - accuracy: 0.7789\n",
            "Epoch 39/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7141 - accuracy: 0.7740\n",
            "Epoch 40/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7367 - accuracy: 0.7740\n",
            "Epoch 41/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6942 - accuracy: 0.7715\n",
            "Epoch 42/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7417 - accuracy: 0.7543\n",
            "Epoch 43/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6623 - accuracy: 0.7936\n",
            "Epoch 44/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6602 - accuracy: 0.7690\n",
            "Epoch 45/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6598 - accuracy: 0.7641\n",
            "Epoch 46/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6762 - accuracy: 0.7740\n",
            "Epoch 47/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7044 - accuracy: 0.7764\n",
            "Epoch 48/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.7813\n",
            "Epoch 49/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6482 - accuracy: 0.7617\n",
            "Epoch 50/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6732 - accuracy: 0.7838\n",
            "Epoch 51/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.7494\n",
            "Epoch 52/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.7740\n",
            "Epoch 53/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6344 - accuracy: 0.7838\n",
            "Epoch 54/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.7764\n",
            "Epoch 55/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6518 - accuracy: 0.7764\n",
            "Epoch 56/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.7838\n",
            "Epoch 57/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5633 - accuracy: 0.7813\n",
            "Epoch 58/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6219 - accuracy: 0.7690\n",
            "Epoch 59/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5886 - accuracy: 0.7838\n",
            "Epoch 60/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5659 - accuracy: 0.8059\n",
            "Epoch 61/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6142 - accuracy: 0.7838\n",
            "Epoch 62/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5623 - accuracy: 0.7912\n",
            "Epoch 63/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6045 - accuracy: 0.7912\n",
            "Epoch 64/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.7666\n",
            "Epoch 65/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.7985\n",
            "Epoch 66/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5979 - accuracy: 0.8084\n",
            "Epoch 67/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5751 - accuracy: 0.7764\n",
            "Epoch 68/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5683 - accuracy: 0.7690\n",
            "Epoch 69/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.7838\n",
            "Epoch 70/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.7764\n",
            "Epoch 71/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.7740\n",
            "Epoch 72/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.7862\n",
            "Epoch 73/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5896 - accuracy: 0.7912\n",
            "Epoch 74/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.7961\n",
            "Epoch 75/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7838\n",
            "Epoch 76/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.7912\n",
            "Epoch 77/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7813\n",
            "Epoch 78/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8059\n",
            "Epoch 79/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.8010\n",
            "Epoch 80/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.7887\n",
            "Epoch 81/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5639 - accuracy: 0.8010\n",
            "Epoch 82/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5579 - accuracy: 0.7838\n",
            "Epoch 83/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7985\n",
            "Epoch 84/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.7912\n",
            "Epoch 85/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.7789\n",
            "Epoch 86/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5277 - accuracy: 0.7912\n",
            "Epoch 87/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.7912\n",
            "Epoch 88/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5855 - accuracy: 0.7862\n",
            "Epoch 89/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.7690\n",
            "Epoch 90/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7887\n",
            "Epoch 91/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5062 - accuracy: 0.7715\n",
            "Epoch 92/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.7862\n",
            "Epoch 93/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5004 - accuracy: 0.7961\n",
            "Epoch 94/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.7912\n",
            "Epoch 95/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.8010\n",
            "Epoch 96/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.7862\n",
            "Epoch 97/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.8108\n",
            "Epoch 98/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.7764\n",
            "Epoch 99/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.8034\n",
            "Epoch 100/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5114 - accuracy: 0.8059\n",
            "Epoch 101/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5563 - accuracy: 0.7813\n",
            "Epoch 102/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.8133\n",
            "Epoch 103/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.7887\n",
            "Epoch 104/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.7961\n",
            "Epoch 105/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.8182\n",
            "Epoch 106/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.7862\n",
            "Epoch 107/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.7936\n",
            "Epoch 108/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.8084\n",
            "Epoch 109/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8108\n",
            "Epoch 110/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8010\n",
            "Epoch 111/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5448 - accuracy: 0.7912\n",
            "Epoch 112/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7912\n",
            "Epoch 113/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.7961\n",
            "Epoch 114/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.7862\n",
            "Epoch 115/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5568 - accuracy: 0.7862\n",
            "Epoch 116/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.7985\n",
            "Epoch 117/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.8084\n",
            "Epoch 118/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.7985\n",
            "Epoch 119/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.8059\n",
            "Epoch 120/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4903 - accuracy: 0.8034\n",
            "Epoch 121/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8034\n",
            "Epoch 122/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.8133\n",
            "Epoch 123/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.7862\n",
            "Epoch 124/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5101 - accuracy: 0.7961\n",
            "Epoch 125/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.7912\n",
            "Epoch 126/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.7985\n",
            "Epoch 127/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.8059\n",
            "Epoch 128/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4655 - accuracy: 0.8157\n",
            "Epoch 129/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.8182\n",
            "Epoch 130/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.8010\n",
            "Epoch 131/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4623 - accuracy: 0.8108\n",
            "Epoch 132/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4937 - accuracy: 0.7912\n",
            "Epoch 133/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.8133\n",
            "Epoch 134/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.8108\n",
            "Epoch 135/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8084\n",
            "Epoch 136/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.7936\n",
            "Epoch 137/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8108\n",
            "Epoch 138/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8133\n",
            "Epoch 139/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.8206\n",
            "Epoch 140/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.8084\n",
            "Epoch 141/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4625 - accuracy: 0.8133\n",
            "Epoch 142/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8010\n",
            "Epoch 143/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.7985\n",
            "Epoch 144/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.8010\n",
            "Epoch 145/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.8157\n",
            "Epoch 146/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.8108\n",
            "Epoch 147/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.8206\n",
            "Epoch 148/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8157\n",
            "Epoch 149/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5098 - accuracy: 0.8231\n",
            "Epoch 150/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8059\n",
            "Epoch 151/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.8206\n",
            "Epoch 152/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8231\n",
            "Epoch 153/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.8084\n",
            "Epoch 154/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.8206\n",
            "Epoch 155/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.8231\n",
            "Epoch 156/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8157\n",
            "Epoch 157/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4543 - accuracy: 0.8157\n",
            "Epoch 158/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.8157\n",
            "Epoch 159/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.8084\n",
            "Epoch 160/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.8034\n",
            "Epoch 161/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.8108\n",
            "Epoch 162/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.8157\n",
            "Epoch 163/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.8256\n",
            "Epoch 164/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.8206\n",
            "Epoch 165/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.8108\n",
            "Epoch 166/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.8010\n",
            "Epoch 167/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.8206\n",
            "Epoch 168/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.8182\n",
            "Epoch 169/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.8182\n",
            "Epoch 170/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4578 - accuracy: 0.8182\n",
            "Epoch 171/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.8108\n",
            "Epoch 172/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.8231\n",
            "Epoch 173/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8256\n",
            "Epoch 174/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8305\n",
            "Epoch 175/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8280\n",
            "Epoch 176/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.8206\n",
            "Epoch 177/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.8280\n",
            "Epoch 178/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.8182\n",
            "Epoch 179/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8280\n",
            "Epoch 180/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8231\n",
            "Epoch 181/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8182\n",
            "Epoch 182/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.8231\n",
            "Epoch 183/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.8084\n",
            "Epoch 184/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.8403\n",
            "Epoch 185/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.8256\n",
            "Epoch 186/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.8305\n",
            "Epoch 187/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4768 - accuracy: 0.8428\n",
            "Epoch 188/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4977 - accuracy: 0.8182\n",
            "Epoch 189/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.8157\n",
            "Epoch 190/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.8182\n",
            "Epoch 191/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.8133\n",
            "Epoch 192/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.8231\n",
            "Epoch 193/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.8354\n",
            "Epoch 194/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.8231\n",
            "Epoch 195/500\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.8354\n",
            "Epoch 196/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.8206\n",
            "Epoch 197/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.8354\n",
            "Epoch 198/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.8305\n",
            "Epoch 199/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.8329\n",
            "Epoch 200/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8575\n",
            "Epoch 201/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.8329\n",
            "Epoch 202/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.8354\n",
            "Epoch 203/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.8477\n",
            "Epoch 204/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4818 - accuracy: 0.8280\n",
            "Epoch 205/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8378\n",
            "Epoch 206/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.8108\n",
            "Epoch 207/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8354\n",
            "Epoch 208/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.8354\n",
            "Epoch 209/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.8133\n",
            "Epoch 210/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.8206\n",
            "Epoch 211/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8329\n",
            "Epoch 212/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8206\n",
            "Epoch 213/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5012 - accuracy: 0.8256\n",
            "Epoch 214/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.8305\n",
            "Epoch 215/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4947 - accuracy: 0.8305\n",
            "Epoch 216/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.8280\n",
            "Epoch 217/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.8305\n",
            "Epoch 218/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.8256\n",
            "Epoch 219/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.8108\n",
            "Epoch 220/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.8157\n",
            "Epoch 221/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8354\n",
            "Epoch 222/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.8280\n",
            "Epoch 223/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.8354\n",
            "Epoch 224/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8501\n",
            "Epoch 225/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8305\n",
            "Epoch 226/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.8231\n",
            "Epoch 227/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.8108\n",
            "Epoch 228/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.8182\n",
            "Epoch 229/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4651 - accuracy: 0.8378\n",
            "Epoch 230/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8231\n",
            "Epoch 231/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.8403\n",
            "Epoch 232/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.8428\n",
            "Epoch 233/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.8403\n",
            "Epoch 234/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8108\n",
            "Epoch 235/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8501\n",
            "Epoch 236/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8206\n",
            "Epoch 237/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.8182\n",
            "Epoch 238/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4651 - accuracy: 0.8550\n",
            "Epoch 239/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5246 - accuracy: 0.8206\n",
            "Epoch 240/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.8428\n",
            "Epoch 241/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.8477\n",
            "Epoch 242/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8501\n",
            "Epoch 243/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8428\n",
            "Epoch 244/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8428\n",
            "Epoch 245/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8403\n",
            "Epoch 246/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8231\n",
            "Epoch 247/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.8305\n",
            "Epoch 248/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8452\n",
            "Epoch 249/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.8550\n",
            "Epoch 250/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.8403\n",
            "Epoch 251/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.8256\n",
            "Epoch 252/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8280\n",
            "Epoch 253/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4818 - accuracy: 0.8231\n",
            "Epoch 254/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.8206\n",
            "Epoch 255/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4709 - accuracy: 0.8477\n",
            "Epoch 256/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4561 - accuracy: 0.8428\n",
            "Epoch 257/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8600\n",
            "Epoch 258/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.8305\n",
            "Epoch 259/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.8354\n",
            "Epoch 260/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4595 - accuracy: 0.8403\n",
            "Epoch 261/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8329\n",
            "Epoch 262/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3906 - accuracy: 0.8796\n",
            "Epoch 263/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.8452\n",
            "Epoch 264/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8305\n",
            "Epoch 265/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4670 - accuracy: 0.8501\n",
            "Epoch 266/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8452\n",
            "Epoch 267/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8354\n",
            "Epoch 268/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8280\n",
            "Epoch 269/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.8305\n",
            "Epoch 270/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.8256\n",
            "Epoch 271/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4433 - accuracy: 0.8452\n",
            "Epoch 272/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8428\n",
            "Epoch 273/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.8329\n",
            "Epoch 274/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.8550\n",
            "Epoch 275/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4635 - accuracy: 0.8403\n",
            "Epoch 276/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.8575\n",
            "Epoch 277/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.8452\n",
            "Epoch 278/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8452\n",
            "Epoch 279/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.8575\n",
            "Epoch 280/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8452\n",
            "Epoch 281/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4507 - accuracy: 0.8575\n",
            "Epoch 282/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8550\n",
            "Epoch 283/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4357 - accuracy: 0.8477\n",
            "Epoch 284/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8600\n",
            "Epoch 285/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.8526\n",
            "Epoch 286/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4604 - accuracy: 0.8452\n",
            "Epoch 287/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8821\n",
            "Epoch 288/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8550\n",
            "Epoch 289/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.8280\n",
            "Epoch 290/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.8673\n",
            "Epoch 291/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.8477\n",
            "Epoch 292/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8722\n",
            "Epoch 293/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3725 - accuracy: 0.8649\n",
            "Epoch 294/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8600\n",
            "Epoch 295/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.8526\n",
            "Epoch 296/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8378\n",
            "Epoch 297/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8575\n",
            "Epoch 298/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8649\n",
            "Epoch 299/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8722\n",
            "Epoch 300/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8501\n",
            "Epoch 301/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8600\n",
            "Epoch 302/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.8550\n",
            "Epoch 303/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8452\n",
            "Epoch 304/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8649\n",
            "Epoch 305/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3988 - accuracy: 0.8649\n",
            "Epoch 306/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.8624\n",
            "Epoch 307/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8526\n",
            "Epoch 308/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4413 - accuracy: 0.8452\n",
            "Epoch 309/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8600\n",
            "Epoch 310/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.8747\n",
            "Epoch 311/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8477\n",
            "Epoch 312/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8722\n",
            "Epoch 313/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8526\n",
            "Epoch 314/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8526\n",
            "Epoch 315/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3703 - accuracy: 0.8845\n",
            "Epoch 316/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8501\n",
            "Epoch 317/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.8354\n",
            "Epoch 318/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4497 - accuracy: 0.8526\n",
            "Epoch 319/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.8452\n",
            "Epoch 320/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.8673\n",
            "Epoch 321/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.8575\n",
            "Epoch 322/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3807 - accuracy: 0.8796\n",
            "Epoch 323/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.8501\n",
            "Epoch 324/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.8600\n",
            "Epoch 325/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.8354\n",
            "Epoch 326/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.8624\n",
            "Epoch 327/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.8428\n",
            "Epoch 328/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8452\n",
            "Epoch 329/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.8575\n",
            "Epoch 330/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8575\n",
            "Epoch 331/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4429 - accuracy: 0.8354\n",
            "Epoch 332/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8550\n",
            "Epoch 333/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.8477\n",
            "Epoch 334/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8722\n",
            "Epoch 335/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8698\n",
            "Epoch 336/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.8526\n",
            "Epoch 337/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8477\n",
            "Epoch 338/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8575\n",
            "Epoch 339/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8526\n",
            "Epoch 340/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.8673\n",
            "Epoch 341/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8771\n",
            "Epoch 342/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4119 - accuracy: 0.8673\n",
            "Epoch 343/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8821\n",
            "Epoch 344/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.8428\n",
            "Epoch 345/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8673\n",
            "Epoch 346/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8894\n",
            "Epoch 347/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.8600\n",
            "Epoch 348/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8870\n",
            "Epoch 349/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8821\n",
            "Epoch 350/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3737 - accuracy: 0.8550\n",
            "Epoch 351/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8722\n",
            "Epoch 352/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3767 - accuracy: 0.8870\n",
            "Epoch 353/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8649\n",
            "Epoch 354/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8600\n",
            "Epoch 355/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4021 - accuracy: 0.8771\n",
            "Epoch 356/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8305\n",
            "Epoch 357/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.8477\n",
            "Epoch 358/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.8722\n",
            "Epoch 359/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8526\n",
            "Epoch 360/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.8747\n",
            "Epoch 361/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.8575\n",
            "Epoch 362/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.8845\n",
            "Epoch 363/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8673\n",
            "Epoch 364/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8600\n",
            "Epoch 365/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.8771\n",
            "Epoch 366/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4095 - accuracy: 0.8600\n",
            "Epoch 367/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8821\n",
            "Epoch 368/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8477\n",
            "Epoch 369/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8771\n",
            "Epoch 370/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8821\n",
            "Epoch 371/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8698\n",
            "Epoch 372/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8870\n",
            "Epoch 373/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8747\n",
            "Epoch 374/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8943\n",
            "Epoch 375/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3840 - accuracy: 0.8870\n",
            "Epoch 376/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8771\n",
            "Epoch 377/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8894\n",
            "Epoch 378/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3526 - accuracy: 0.8747\n",
            "Epoch 379/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8894\n",
            "Epoch 380/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.8894\n",
            "Epoch 381/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3657 - accuracy: 0.8870\n",
            "Epoch 382/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3755 - accuracy: 0.8919\n",
            "Epoch 383/500\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8845\n",
            "Epoch 384/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8919\n",
            "Epoch 385/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3580 - accuracy: 0.8943\n",
            "Epoch 386/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8845\n",
            "Epoch 387/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.9165\n",
            "Epoch 388/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8919\n",
            "Epoch 389/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3601 - accuracy: 0.8919\n",
            "Epoch 390/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8870\n",
            "Epoch 391/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8870\n",
            "Epoch 392/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.8624\n",
            "Epoch 393/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8870\n",
            "Epoch 394/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8771\n",
            "Epoch 395/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8845\n",
            "Epoch 396/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8600\n",
            "Epoch 397/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8624\n",
            "Epoch 398/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.9017\n",
            "Epoch 399/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3692 - accuracy: 0.8771\n",
            "Epoch 400/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8698\n",
            "Epoch 401/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3869 - accuracy: 0.8673\n",
            "Epoch 402/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8919\n",
            "Epoch 403/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8821\n",
            "Epoch 404/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.8673\n",
            "Epoch 405/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8821\n",
            "Epoch 406/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8673\n",
            "Epoch 407/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.8501\n",
            "Epoch 408/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.8452\n",
            "Epoch 409/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.8673\n",
            "Epoch 410/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8993\n",
            "Epoch 411/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8722\n",
            "Epoch 412/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8894\n",
            "Epoch 413/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3704 - accuracy: 0.8845\n",
            "Epoch 414/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8722\n",
            "Epoch 415/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8845\n",
            "Epoch 416/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8894\n",
            "Epoch 417/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8894\n",
            "Epoch 418/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8894\n",
            "Epoch 419/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.9017\n",
            "Epoch 420/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.9066\n",
            "Epoch 421/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3669 - accuracy: 0.9017\n",
            "Epoch 422/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.9140\n",
            "Epoch 423/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.8894\n",
            "Epoch 424/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.8919\n",
            "Epoch 425/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.8673\n",
            "Epoch 426/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8943\n",
            "Epoch 427/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.9091\n",
            "Epoch 428/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3902 - accuracy: 0.8821\n",
            "Epoch 429/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.9140\n",
            "Epoch 430/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8943\n",
            "Epoch 431/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8747\n",
            "Epoch 432/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3736 - accuracy: 0.8894\n",
            "Epoch 433/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.9066\n",
            "Epoch 434/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8771\n",
            "Epoch 435/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8870\n",
            "Epoch 436/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3692 - accuracy: 0.8968\n",
            "Epoch 437/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8993\n",
            "Epoch 438/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8747\n",
            "Epoch 439/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8919\n",
            "Epoch 440/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8943\n",
            "Epoch 441/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3730 - accuracy: 0.8919\n",
            "Epoch 442/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.9042\n",
            "Epoch 443/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3791 - accuracy: 0.8919\n",
            "Epoch 444/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8968\n",
            "Epoch 445/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8919\n",
            "Epoch 446/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8870\n",
            "Epoch 447/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3871 - accuracy: 0.8993\n",
            "Epoch 448/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.9091\n",
            "Epoch 449/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3807 - accuracy: 0.8821\n",
            "Epoch 450/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8870\n",
            "Epoch 451/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8821\n",
            "Epoch 452/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8968\n",
            "Epoch 453/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3878 - accuracy: 0.8894\n",
            "Epoch 454/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4023 - accuracy: 0.8919\n",
            "Epoch 455/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.9017\n",
            "Epoch 456/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3566 - accuracy: 0.8894\n",
            "Epoch 457/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.8796\n",
            "Epoch 458/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8747\n",
            "Epoch 459/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8722\n",
            "Epoch 460/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.9140\n",
            "Epoch 461/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.8943\n",
            "Epoch 462/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.9017\n",
            "Epoch 463/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3618 - accuracy: 0.9042\n",
            "Epoch 464/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8870\n",
            "Epoch 465/500\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3535 - accuracy: 0.9189\n",
            "Epoch 466/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.9066\n",
            "Epoch 467/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.9115\n",
            "Epoch 468/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.9091\n",
            "Epoch 469/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.8796\n",
            "Epoch 470/500\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4791 - accuracy: 0.8796\n",
            "Epoch 471/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3705 - accuracy: 0.8943\n",
            "Epoch 472/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8747\n",
            "Epoch 473/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8771\n",
            "Epoch 474/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.8968\n",
            "Epoch 475/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8943\n",
            "Epoch 476/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.8771\n",
            "Epoch 477/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3745 - accuracy: 0.9140\n",
            "Epoch 478/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.9017\n",
            "Epoch 479/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.9017\n",
            "Epoch 480/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3699 - accuracy: 0.9091\n",
            "Epoch 481/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.9115\n",
            "Epoch 482/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8894\n",
            "Epoch 483/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8943\n",
            "Epoch 484/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3665 - accuracy: 0.9017\n",
            "Epoch 485/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3473 - accuracy: 0.9140\n",
            "Epoch 486/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8870\n",
            "Epoch 487/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3281 - accuracy: 0.9189\n",
            "Epoch 488/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.9091\n",
            "Epoch 489/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3787 - accuracy: 0.9042\n",
            "Epoch 490/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8919\n",
            "Epoch 491/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3617 - accuracy: 0.9115\n",
            "Epoch 492/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.9263\n",
            "Epoch 493/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.9017\n",
            "Epoch 494/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3678 - accuracy: 0.9140\n",
            "Epoch 495/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.9189\n",
            "Epoch 496/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.9140\n",
            "Epoch 497/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3661 - accuracy: 0.9042\n",
            "Epoch 498/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.9312\n",
            "Epoch 499/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.9042\n",
            "Epoch 500/500\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3217 - accuracy: 0.9238\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.2898 - accuracy: 0.9273\n",
            "\n",
            "\n",
            "Test Loss 0.2897992506623268, Test Accuracy 92.72727370262146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDEbE2CbVZns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "39f4df9f-a05a-45b9-e67a-df4828cc817d"
      },
      "source": [
        "# Show some results\n",
        "predictions = model.predict(test_data)\n",
        "for prediction, CHD in zip(predictions[:50], list(test_data)[0][1][:50]):\n",
        "  print(\"Predicted Coronary Heart Disease: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"YES Coronary Heart Disease\" if bool(CHD) else \"NO Coronary Heart Disease\"))"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Coronary Heart Disease: 0.30%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 2.13%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.88%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.60%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 8.64%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 2.75%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.66%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 1.30%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.11%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.59%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 1.16%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 96.87%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 17.52%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 6.43%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 58.18%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 1.45%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 13.87%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.77%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 1.09%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 8.50%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.29%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 4.61%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 9.30%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 85.11%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.02%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 3.10%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.46%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 83.59%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 38.13%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 1.17%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 66.77%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 92.61%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.03%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 3.50%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.81%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.00%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 52.47%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 8.77%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 83.09%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 68.99%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 99.97%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 11.08%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.33%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 0.02%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 53.59%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 5.74%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 59.40%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 39.01%  | Actual outcome:  YES Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 7.59%  | Actual outcome:  NO Coronary Heart Disease\n",
            "Predicted Coronary Heart Disease: 69.65%  | Actual outcome:  NO Coronary Heart Disease\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}